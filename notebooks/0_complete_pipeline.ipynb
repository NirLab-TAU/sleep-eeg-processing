{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory notes:\n",
    "This notebook presents minimal functionality needed to go through the cleaning, ICA, spectral, and event analysis stages.\n",
    "* For the cleaning part, the functionality consists of resampling, filtering, bad channels and bad data spans annotation, and bad channels interpolation.\n",
    "* For the ICA part, it is fitting and selecting components you want to exclude.\n",
    "* For the spectral analyses part, it is spectrogram+hypnogram, PSD per sleep stage, and topomap per sleep stage per frequency band.\n",
    "* For the detection of the events, it is spindles, slow waves, and rapid eye movements detection and analysis.\n",
    "\n",
    "For the extended functionality check out the corresponding notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sleepeegpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### This code contains widgets that will be previewed later in the notebook. ######\n",
    "####### Run this code and continue. ######\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "use_example_set = widgets.RadioButtons(\n",
    "    options=[True, False],\n",
    "    description='Use example set?',\n",
    "    value=True\n",
    ")\n",
    "bad_channels_selection = widgets.RadioButtons(\n",
    "    options=['automatically', 'manually', \"from-file\"],\n",
    "    description='Clean Bad Channels:',\n",
    "    value='from-file'\n",
    ")\n",
    "annotations_selection = widgets.RadioButtons(\n",
    "    options=[\"automatically\", \"manually\", \"from-file\"],\n",
    "    description='Clean bad epochs Annotations:',\n",
    "    value=\"from-file\"\n",
    ")\n",
    "\n",
    "hypno_selection = widgets.RadioButtons(\n",
    "    options=[\"automatically\", \"from-file\"],\n",
    "    description='Hypnogram:',\n",
    "    value=\"from-file\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "from sleepeegpy.pipeline import (\n",
    "    CleaningPipe, ICAPipe, SpectralPipe, \n",
    "    SpindlesPipe, SlowWavesPipe, RapidEyeMovementsPipe)\n",
    "from sleepeegpy.dashboard import create_dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Input Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all the input files are assumed to be saved in <b>input_files</b>, which will be created (if not already exist) in the notebook path. Change the following strings to use another path.\n",
    "Changing the output directory is also optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "\n",
    "output_dir  = \"output_folder\" # Output path and name can be changed here\n",
    "input_dir = \"input_files\" # input files dir can be changed here\n",
    "makedirs(input_dir, exist_ok=True)\n",
    "makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline preference:\n",
    "Change the values according to how you want to use the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53abc284e184bd2bac8a074251b823e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Use example set?', options=(True, False), value=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba4fba3cc2743de85327ca62163ae27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Clean Bad Channels:', index=2, options=('automatically', 'manually', 'from-file'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bd5fb39bdf4b5298b80bfdc73f4b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Clean bad epochs Annotations:', index=2, options=('automatically', 'manually', 'from…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15008b0c65f449fa8064c01610890eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Hypnogram:', index=1, options=('automatically', 'from-file'), value='from-file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(use_example_set)\n",
    "display(bad_channels_selection)\n",
    "display(annotations_selection)\n",
    "display(hypno_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add requested files\n",
    "Run the code below, add all requested files (according to your preference) in the input file, and write their names.\n",
    "\n",
    "Instructions:\n",
    "- Put your files in the input directory.\n",
    "- EEG file must include a montage that works with mne.read_raw.\n",
    "- For more information about the mne.read_raw supported formats, see [mne documentation](https://mne.tools/stable/generated/mne.io.Raw.html)\n",
    "- If your file has no montage, but there is a channel mapping, you can add montage in the cleaning part (there is an example below of one way to add it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you use your own files (not the example set), write the relevant filenames below. ###\n",
    "\n",
    "subject_code = \"DK8\" # The subject code that will appear in the dashboard\n",
    "eeg_file = \"resampled_raw.fif\"\n",
    "bad_channels = \"bad_channels.txt\"\n",
    "annotations = \"annotations.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using hypnogram file:\n",
    "* Modify your hypnogram file name (Point-per-row type of hypnogram) below. \n",
    "* If needed, change the Hypnogram's sampling frequency\n",
    "* If you don't have a hypnogram file, follow the next notebook instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypnogram_filename = \"staging.txt\"\n",
    "hypno_freq = 1 # If required, change the Hypnogram's sampling frequency (Visbrain's hypnograms default to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hypnogram prediction arguments\n",
    "<b>If you don't have hypnogram file</b>, choose prediction arguments.\n",
    "These values will use [YASA's algorithm](https://raphaelvallat.com/yasa/build/html/generated/yasa.SleepStaging.html#yasa.SleepStaging) to create a new hypnogram. \n",
    "\n",
    "<b> Make sure the selected channel names exist in your montage </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hypno_selection.value==\"automatically\":\n",
    "    hypnogram_path = \"predict\"\n",
    "#### If you selected automatic hypnogram, select prediction arguments. ####\n",
    "    hypno_predict_arguments = {\n",
    "    \"eeg_name\": \"E183\", #(C4)\n",
    "    \"eog_name\": \"E252\", #(EOG1)\n",
    "    \"emg_name\": \"E247\",\n",
    "    \"ref_name\" : \"E26\",\n",
    "    \"save\": False\n",
    "    }\n",
    "else:\n",
    "    hypno_predict_arguments = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust variables\n",
    "* If required, change `n_components` - should equal or less than the number of channels. see [more information](https://mne.tools/stable/generated/mne.preprocessing.ICA.html)\n",
    "* Modify the picked channel. `picked_channel` represents the EEG channel selected for plotting and computations of hypnospectrogram, PSDs, and TFRs.\n",
    "* Modify the variable in the next notebook cells, to have separate channels for each plot.\n",
    "* Modify loc_chname and roc_chname (EOG). For more information see: [Left and Right Ocular Canthi](https://raphaelvallat.com/yasa/build/html/generated/yasa.rem_detect.html).\n",
    "* Make sure all channel names are part of the montage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 30\n",
    "picked_channel = 'E101' # (Pz)\n",
    "loc_chname = \"E252\" # (EOG1)\n",
    "roc_chname = \"E226\" # (EOG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> You can now run the notebook (you can change values according to your needs)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_example_set.value:\n",
    "    cache_dir = pooch.os_cache(\"sleepeegpy_dataset\")\n",
    "    doi = \"10.5281/zenodo.10362189\"\n",
    "    odie = pooch.create(\n",
    "        path=cache_dir,\n",
    "        base_url=f\"doi:{doi}\",\n",
    "    )\n",
    "    odie.load_registry_from_doi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'nap_bad_channels.txt' from 'doi:10.5281/zenodo.10362189/nap_bad_channels.txt' to '/Users/yardenmezi/Library/Caches/sleepeegpy_dataset'.\n",
      "Downloading file 'nap_annotations.txt' from 'doi:10.5281/zenodo.10362189/nap_annotations.txt' to '/Users/yardenmezi/Library/Caches/sleepeegpy_dataset'.\n",
      "Downloading file 'nap_resampled_raw.fif' from 'doi:10.5281/zenodo.10362189/nap_resampled_raw.fif' to '/Users/yardenmezi/Library/Caches/sleepeegpy_dataset'.\n",
      " 64%|███████████████████████▌             | 1.27G/2.00G [01:56<00:50, 14.3MB/s]"
     ]
    }
   ],
   "source": [
    "if use_example_set.value:\n",
    "## Nap dataset files: ##\n",
    "    bad_channels = odie.fetch(\"nap_bad_channels.txt\")\n",
    "    annotations = odie.fetch(\"nap_annotations.txt\")\n",
    "    path_to_eeg = odie.fetch(\"nap_resampled_raw.fif\", progressbar=True)\n",
    "    if hypno_selection.value == \"from-file\":\n",
    "        hypnogram_path = odie.fetch(\"nap_staging.txt\", progressbar=True) \n",
    "else:    \n",
    "    path_to_eeg = os.path.join(input_dir,eeg_file)\n",
    "    if hypno_selection.value == \"from-file\":\n",
    "        hypnogram_path = os.path.join(input_dir,hypnogram_filename)\n",
    "    bad_channels = None if bad_channels_selection == \"automatically\" else os.path.join(input_dir,bad_channels) \n",
    "    annotations = None if annotations_selection == \"automatically\" else os.path.join(input_dir,annotations) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `CleaningPipe` object by providing it with path to eeg file and output directory in which you want the data to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = CleaningPipe(\n",
    "    path_to_eeg=path_to_eeg,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Adding montage example ####\n",
    "# import mne\n",
    "# channels_map = {\"E59\": \"C3\", \"E183\": \"C4\", \"E36\": \"F3\", \"E224\": \"F4\", \"E47\": \"F7\", \"E2\": \"F8\",\"E37\": \"Fp1\", \"E18\": \"Fp2\", \"E21\": \"Fz\", \"E116\": \"O1\", \"E150\": \"O2\", \"E87\": \"P3\", \"E153\": \"P4\", \"E101\": \"Pz\",\"E69\": \"T3\", \"E202\": \"T4\", \"E96\": \"T5\", \"E170\": \"T6\", \"E94\": \"A1\", \"E190\": \"A2\"}\n",
    "# current_channel_names = set(pipe.mne_raw.ch_names)\n",
    "# channels_to_drop = list(current_channel_names - set(channels_map.keys()))\n",
    "# pipe.mne_raw.drop_channels(channels_to_drop)\n",
    "# mne.rename_channels(pipe.mne_raw.info, channels_map)\n",
    "# montage = mne.channels.make_standard_montage('standard_1020')\n",
    "# pipe.mne_raw.set_montage(montage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "This can take more than an hour depending on eeg signal size and specs of the computer you're running the analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.resample(sfreq=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.filter(l_freq=0.75, h_freq=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.notch(freqs=\"50s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select bad channels and epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If manually bad channels were selected, select bad channels in the pop-up window.\n",
    "Note that automatically bad channels selection takes time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_channels_selection.value == \"manually\":\n",
    "    pipe.plot(save_bad_channels=True)\n",
    "elif bad_channels_selection.value == \"automatically\":\n",
    "    bad_channels = pipe.auto_detect_bad_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.read_bad_channels(path = None if bad_channels_selection.value == \"Manually\" else bad_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select bad epochs\n",
    "\n",
    "Click \"a\" -> \"Add description\" -> Enter BAD_EPOCH -> Annotate bad data spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annotations_selection\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanually\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     pipe\u001b[38;5;241m.\u001b[39mplot(butterfly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_annotations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)    \n\u001b[1;32m      3\u001b[0m     pipe\u001b[38;5;241m.\u001b[39mread_annotations()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'annotations_selection' is not defined"
     ]
    }
   ],
   "source": [
    "if annotations_selection.value == \"manually\":\n",
    "    pipe.plot(butterfly=True, save_annotations=True,overwrite=True)    \n",
    "    pipe.read_annotations()\n",
    "elif annotations_selection.value == \"from-file\":\n",
    "    pipe.read_annotations(path = annotations)\n",
    "elif annotations_selection.value == \"automatically\":\n",
    "    pipe.auto_set_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_dashboard(\n",
    "    subject_code=subject_code, \n",
    "    prec_pipe=pipe, \n",
    "    hypno_psd_pick=picked_channel,\n",
    "    hypnogram= hypnogram_path,\n",
    "    predict_hypno_args = hypno_predict_arguments,\n",
    "    hypno_freq=hypno_freq,\n",
    "    reference=\"average\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the preceding (cleaning) pipe to the ICAPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_pipe = ICAPipe(prec_pipe=pipe, n_components=n_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the ICA on the 1 Hz high-pass filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_pipe.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually inspect ICA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_pipe.plot_sources()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass to the `exclude` argument indices of components you want to remove from the raw signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_pipe.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the preceding (cleaning or ICA) pipe to the SpectralPipe. Also provide pass to the hypnogram and don't forget to pass its frequency to the corresponding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_pipe = SpectralPipe(\n",
    "    prec_pipe=ica_pipe,\n",
    "    path_to_hypno=hypnogram_path,\n",
    "    hypno_freq=hypno_freq,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a hypnogram, `predict_hypno` will use [YASA's algorithm](https://raphaelvallat.com/yasa/build/html/generated/yasa.SleepStaging.html#yasa.SleepStaging). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hypnogram_path is None:\n",
    "    spectral_pipe.predict_hypno(\n",
    "    eeg_name = hypno_predict_arguments[\"eeg_name\"],\n",
    "    eog_name = hypno_predict_arguments[\"eog_name\"],\n",
    "    emg_name =  hypno_predict_arguments[\"emg_name\"],\n",
    "    ref_name = hypno_predict_arguments[\"ref_name\"],\n",
    "    save=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, picked_channel will be used to calculate spectrogram. You can pass another electrode name (make sure it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_pipe.plot_hypnospectrogram(picks=[picked_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_pipe.compute_psd(\n",
    "    sleep_stages={\"Wake\": 0, \"N1\": 1, \"N2/3\": (2, 3), \"REM\": 4},\n",
    "    reference=\"average\",\n",
    "    # Additional arguments passed to the Welch method:\n",
    "    n_fft=1024,\n",
    "    n_per_seg=1024,\n",
    "    n_overlap=512,\n",
    "    window=\"hamming\",\n",
    "    verbose=False\n",
    ")\n",
    "spectral_pipe.plot_psds(picks=[picked_channel], psd_range=(-30, 30))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a collage with rows for sleep stages and columns for bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_pipe.plot_topomap_collage()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the preceding (cleaning or ICA or spectral) pipe to one of the SpindlesPipe, SlowWavesPipe, or RapidEyeMovementsPipe. If the preceding is cleaning or ICA - provide a path to the hypnogram and don't forget to pass its frequency to the corresponding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_pipe = SpindlesPipe(prec_pipe=spectral_pipe)\n",
    "\n",
    "spindles_pipe.detect()\n",
    "spindles_pipe.plot_average(\n",
    "    center=\"Peak\",\n",
    "    hue=\"Stage\",\n",
    "    time_before=1,\n",
    "    time_after=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_pipe.results.summary(grp_chan=False, grp_stage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_pipe.compute_tfr(freqs=(10, 20), n_freqs=100, time_before=1, time_after=1)\n",
    "spindles_pipe.tfrs[\"N2\"].plot([picked_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_waves_pipe = SlowWavesPipe(prec_pipe=spindles_pipe)\n",
    "slow_waves_pipe.detect()\n",
    "\n",
    "slow_waves_pipe.plot_average(\n",
    "    center=\"NegPeak\",\n",
    "    hue=\"Stage\",\n",
    "    time_before=0.4,\n",
    "    time_after=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_waves_pipe.compute_tfr(\n",
    "    freqs=(0.5, 5), n_freqs=100, time_before=4, time_after=4, n_cycles=2\n",
    ")\n",
    "ploted_channel = \"VREF\" # Cz \n",
    "slow_waves_pipe.tfrs[\"N3\"].plot([picked_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rems_pipe = RapidEyeMovementsPipe(prec_pipe=slow_waves_pipe)\n",
    "\n",
    "rems_pipe.detect(\n",
    "    loc_chname=loc_chname,\n",
    "    roc_chname=roc_chname,\n",
    ")\n",
    "\n",
    "rems_pipe.plot_average(\n",
    "    center=\"Peak\",\n",
    "    time_before=0.5,\n",
    "    time_after=0.5,\n",
    "    filt=(None, None),\n",
    "    mask=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7e6a3ad0af7de53e72789e0b82b3fd5c64743c0f9fcf843fd4113b6e74b9b71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
